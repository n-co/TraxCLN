Training: enter either full_batch or mini_batch folder. 
Before training, you should create 3 folders: log, bestModels and models. 
  log:        training log for each training time. 
  bestModels: .h5df files storing parameters at the epoch of the best validation performance. 
  models:     .json files storing the Keras models.

Command:
python training.py [-opt option_val]

-opt      default_option (using / for separating possible options, ... is any value)
  -model    Highway (Highway/Dense)
  -data     pubmed (pubmed/BoW_movielens)
  -dim      50 (the hidden dimension of the column network, this hyper-param should be tuned)
  -nlayers  10 (the number of highway layer, should be 10)
  -nmean    1 (the constant z in the paper, should be between 1 and the number of relation types)
  -reg      dr (dr/x. dr means dropout and x means no regularization)
  -shared   1 (0/1. 1: parameter sharing among highway layers, 0: otherwise)
  -opt      RMS (Adam/RMS. The optimizer)
  -seed     1234 (any value - for reproducing the experiments)
  -batch    100 (batch size in the mini_batch training only)
  -y        1 (in the case of multi-label, e.g., movielens, each label is trained separetely. This option is for choosing what label is trained)

Example:
Training the first label of BoW_movielens in full-batch mode: 
  cd full_batch
  python training.py -model Highway -data BoW_movielens -dim 40 -nlayers 10 -nmean 3 -y 0
  
Training pubmed dataset in mini-batch mode:
  cd mini_batch
  python training.py -model Highway -data pubmed -dim 40 -layers 10 -nmean 2 -batch 100
